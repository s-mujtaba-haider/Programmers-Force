{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331506e1-8f36-4426-ac87-70096b9c2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üß† Cell 1 ‚Äî Train Custom CNN Model\n",
    "# ========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ======================\n",
    "# Transforms\n",
    "# ======================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# Datasets & Loaders\n",
    "# ======================\n",
    "data_dir = \"dataset\"\n",
    "\n",
    "train_ds = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n",
    "test_ds  = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=val_transform)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "class_names = train_ds.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# ======================\n",
    "# Model Definition\n",
    "# ======================\n",
    "class AntiSpoofNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AntiSpoofNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # block 1\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 2\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 3\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 4\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 5\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 * 7 * 7, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ======================\n",
    "# Training setup\n",
    "# ======================\n",
    "model = AntiSpoofNet(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "# ======================\n",
    "# Training Loop\n",
    "# ======================\n",
    "best_val_acc = 0.0\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100*correct/total)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    scheduler.step(val_acc)\n",
    "    print(f\"Epoch {epoch+1} done. Train Acc: {100*correct/total:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_customcnn.pth\")\n",
    "        print(\"‚úÖ Saved best model\")\n",
    "\n",
    "print(\"Training complete. Best Val Accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1edf33-43e1-40d1-a3a1-c96df2f9c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üß™ Cell 2 ‚Äî Test on test set\n",
    "# ========================================\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "model = AntiSpoofNet(num_classes=2).to(device)\n",
    "model.load_state_dict(torch.load(\"best_customcnn.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "\n",
    "real_acc = report[\"real\"][\"recall\"] * 100\n",
    "spoof_acc = report[\"spoof\"][\"recall\"] * 100\n",
    "overall_acc = (np.trace(cm) / np.sum(cm)) * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Overall Accuracy: {overall_acc:.2f}%\")\n",
    "print(f\"üé≠ Real Accuracy: {real_acc:.2f}%\")\n",
    "print(f\"üïµÔ∏è Spoof Accuracy: {spoof_acc:.2f}%\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa216a-af25-4446-92e3-1e53d6203a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üöÄ Cell 3 ‚Äî Evaluate on Custom Folder\n",
    "# ========================================\n",
    "custom_dir = \"custom_folder\"  # <-- Your custom unseen dataset folder\n",
    "\n",
    "custom_ds = datasets.ImageFolder(custom_dir, transform=val_transform)\n",
    "custom_loader = DataLoader(custom_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"Custom classes:\", custom_ds.classes)\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(custom_loader, desc=\"Evaluating Custom Folder\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "cm_custom = confusion_matrix(all_labels, all_preds)\n",
    "report_custom = classification_report(all_labels, all_preds, target_names=custom_ds.classes, output_dict=True)\n",
    "\n",
    "real_acc = report_custom[\"real\"][\"recall\"] * 100\n",
    "spoof_acc = report_custom[\"spoof\"][\"recall\"] * 100\n",
    "overall_acc = (np.trace(cm_custom) / np.sum(cm_custom)) * 100\n",
    "\n",
    "print(f\"\\nüßæ Custom Folder Evaluation Results:\")\n",
    "print(f\"‚úÖ Overall Accuracy: {overall_acc:.2f}%\")\n",
    "print(f\"üé≠ Real Accuracy: {real_acc:.2f}%\")\n",
    "print(f\"üïµÔ∏è Spoof Accuracy: {spoof_acc:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=custom_ds.classes, yticklabels=custom_ds.classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Custom Folder)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
