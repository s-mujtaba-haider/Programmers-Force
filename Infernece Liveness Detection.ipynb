{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331506e1-8f36-4426-ac87-70096b9c2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üß† Cell 1 ‚Äî Train Custom CNN Model\n",
    "# ========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ======================\n",
    "# Transforms\n",
    "# ======================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# Datasets & Loaders\n",
    "# ======================\n",
    "data_dir = \"dataset\"\n",
    "\n",
    "train_ds = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=val_transform)\n",
    "test_ds  = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=val_transform)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "class_names = train_ds.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# ======================\n",
    "# Model Definition\n",
    "# ======================\n",
    "class AntiSpoofNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AntiSpoofNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # block 1\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 2\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 3\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 4\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 5\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 * 7 * 7, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# ======================\n",
    "# Training setup\n",
    "# ======================\n",
    "model = AntiSpoofNet(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "# ======================\n",
    "# Training Loop\n",
    "# ======================\n",
    "best_val_acc = 0.0\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100*correct/total)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    scheduler.step(val_acc)\n",
    "    print(f\"Epoch {epoch+1} done. Train Acc: {100*correct/total:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_customcnn.pth\")\n",
    "        print(\"‚úÖ Saved best model\")\n",
    "\n",
    "print(\"Training complete. Best Val Accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1edf33-43e1-40d1-a3a1-c96df2f9c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üß™ Cell 2 ‚Äî Test on test set\n",
    "# ========================================\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "model = AntiSpoofNet(num_classes=2).to(device)\n",
    "model.load_state_dict(torch.load(\"best_customcnn.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "\n",
    "real_acc = report[\"real\"][\"recall\"] * 100\n",
    "spoof_acc = report[\"spoof\"][\"recall\"] * 100\n",
    "overall_acc = (np.trace(cm) / np.sum(cm)) * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Overall Accuracy: {overall_acc:.2f}%\")\n",
    "print(f\"üé≠ Real Accuracy: {real_acc:.2f}%\")\n",
    "print(f\"üïµÔ∏è Spoof Accuracy: {spoof_acc:.2f}%\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa216a-af25-4446-92e3-1e53d6203a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# üöÄ Cell 3 ‚Äî Evaluate on Custom Folder\n",
    "# ========================================\n",
    "custom_dir = \"custom_folder\"  # <-- Your custom unseen dataset folder\n",
    "\n",
    "custom_ds = datasets.ImageFolder(custom_dir, transform=val_transform)\n",
    "custom_loader = DataLoader(custom_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"Custom classes:\", custom_ds.classes)\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(custom_loader, desc=\"Evaluating Custom Folder\"):\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "cm_custom = confusion_matrix(all_labels, all_preds)\n",
    "report_custom = classification_report(all_labels, all_preds, target_names=custom_ds.classes, output_dict=True)\n",
    "\n",
    "real_acc = report_custom[\"real\"][\"recall\"] * 100\n",
    "spoof_acc = report_custom[\"spoof\"][\"recall\"] * 100\n",
    "overall_acc = (np.trace(cm_custom) / np.sum(cm_custom)) * 100\n",
    "\n",
    "print(f\"\\nüßæ Custom Folder Evaluation Results:\")\n",
    "print(f\"‚úÖ Overall Accuracy: {overall_acc:.2f}%\")\n",
    "print(f\"üé≠ Real Accuracy: {real_acc:.2f}%\")\n",
    "print(f\"üïµÔ∏è Spoof Accuracy: {spoof_acc:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=custom_ds.classes, yticklabels=custom_ds.classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Custom Folder)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2851d78-a1f3-447d-b316-1554ce7f68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Robust Webcam Inference Cell\n",
    "# ===========================\n",
    "# Paste into one Jupyter notebook cell and run.\n",
    "# Make sure your model weights \"best_customcnn.pth\" are in the working directory (or change path below).\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# -----------------------\n",
    "# Device\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------\n",
    "# Model architecture (must match your trained model)\n",
    "# -----------------------\n",
    "class AntiSpoofNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AntiSpoofNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # block 1\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 2\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 3\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 4\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # block 5\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 * 7 * 7, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# -----------------------\n",
    "# Load model weights\n",
    "# -----------------------\n",
    "model = AntiSpoofNet(num_classes=2).to(device)\n",
    "weights_path = \"best_customcnn.pth\"  # change if needed\n",
    "state = torch.load(weights_path, map_location=device)\n",
    "try:\n",
    "    model.load_state_dict(state)\n",
    "except Exception as e:\n",
    "    # permissive load in case state dict nested or saved differently\n",
    "    if 'state_dict' in state:\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "    else:\n",
    "        raise e\n",
    "model.eval()\n",
    "print(\"Loaded model weights from\", weights_path)\n",
    "\n",
    "# -----------------------\n",
    "# Transforms (same normalization used during training)\n",
    "# -----------------------\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# -----------------------\n",
    "# Face detector: try RetinaFace, fallback to MTCNN\n",
    "# -----------------------\n",
    "use_retina = False\n",
    "detector = None\n",
    "try:\n",
    "    from retinaface import RetinaFace\n",
    "    use_retina = True\n",
    "    print(\"Using RetinaFace for detection (retinaface package).\")\n",
    "except Exception as e:\n",
    "    print(\"RetinaFace not available, falling back to MTCNN from facenet-pytorch.\")\n",
    "    try:\n",
    "        from facenet_pytorch import MTCNN\n",
    "        detector = MTCNN(keep_all=True, device=device if str(device).startswith(\"cuda\") else \"cpu\")\n",
    "        print(\"Using MTCNN for detection.\")\n",
    "    except Exception as e2:\n",
    "        raise RuntimeError(\"No face detector available. Install retinaface or facenet-pytorch.\") from e2\n",
    "\n",
    "# -----------------------\n",
    "# Utilities: IoU, expand box, FFT score\n",
    "# -----------------------\n",
    "def iou(boxA, boxB):\n",
    "    # boxes in (x1,y1,x2,y2)\n",
    "    xA = max(boxA[0], boxB[0]); yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2]); yB = min(boxA[3], boxB[3])\n",
    "    interW = max(0, xB - xA); interH = max(0, yB - yA)\n",
    "    inter = interW * interH\n",
    "    boxAArea = max(0, (boxA[2]-boxA[0])) * max(0, (boxA[3]-boxA[1]))\n",
    "    boxBArea = max(0, (boxB[2]-boxB[0])) * max(0, (boxB[3]-boxB[1]))\n",
    "    den = boxAArea + boxBArea - inter\n",
    "    return inter / den if den > 0 else 0.0\n",
    "\n",
    "def expand_box(box, scale, img_w, img_h):\n",
    "    x1,y1,x2,y2 = box\n",
    "    w = x2 - x1; h = y2 - y1\n",
    "    cx = x1 + w/2; cy = y1 + h/2\n",
    "    nw = w * scale; nh = h * scale\n",
    "    nx1 = int(max(0, cx - nw/2)); ny1 = int(max(0, cy - nh/2))\n",
    "    nx2 = int(min(img_w, cx + nw/2)); ny2 = int(min(img_h, cy + nh/2))\n",
    "    return (nx1, ny1, nx2, ny2)\n",
    "\n",
    "def fft_spoof_score(bgr_crop):\n",
    "    # Returns a heuristic 0..1 score: higher -> more \"spoof-like\" spectral signature\n",
    "    gray = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2GRAY)\n",
    "    # small blur to reduce noise bias\n",
    "    gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    f = np.fft.fft2(gray)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude = np.abs(fshift)\n",
    "    # avoid log(0)\n",
    "    mag = np.log1p(magnitude)\n",
    "    h, w = mag.shape\n",
    "    # center low-freq region radius\n",
    "    cx, cy = w//2, h//2\n",
    "    # create mask for high frequency region\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    r = np.sqrt((X - cx)**2 + (Y - cy)**2)\n",
    "    # threshold radius: 25% of max dimension\n",
    "    rad = max(h, w) * 0.25\n",
    "    hf_mask = (r > rad)\n",
    "    hf_energy = mag[hf_mask].sum()\n",
    "    total_energy = mag.sum() + 1e-8\n",
    "    hf_ratio = hf_energy / total_energy\n",
    "    # some heuristics: screens and prints often create higher periodic energy -> higher hf_ratio\n",
    "    # scale ratio to 0..1 (expected hf_ratio ~0.05..0.5)\n",
    "    score = np.clip((hf_ratio - 0.05) / (0.45 - 0.05), 0.0, 1.0)\n",
    "    return float(score)\n",
    "\n",
    "# -----------------------\n",
    "# Tracking small state per face with simple IOU linking\n",
    "# -----------------------\n",
    "class Track:\n",
    "    def __init__(self, box, track_id):\n",
    "        self.box = box\n",
    "        self.id = track_id\n",
    "        self.last_seen = 0\n",
    "        self.pred_queue = deque(maxlen=7)   # store recent softmax probabilities (spoof prob)\n",
    "        self.last_center = ((box[0]+box[2])/2, (box[1]+box[3])/2)\n",
    "\n",
    "tracks = []\n",
    "next_track_id = 0\n",
    "FRAME_COUNTER = 0\n",
    "IOU_MATCH_THRESH = 0.35\n",
    "\n",
    "# -----------------------\n",
    "# Inference helpers\n",
    "# -----------------------\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "def predict_on_crop(bgr_crop, upsample_small=True):\n",
    "    # bgr_crop: numpy BGR image\n",
    "    # returns spoof_prob (float 0..1)\n",
    "    h, w = bgr_crop.shape[:2]\n",
    "    # if very small, upsample to keep texture information (won't add info but matches training scale)\n",
    "    if upsample_small and max(h,w) < 80:\n",
    "        scale = int(np.ceil(224 / max(h,w)))\n",
    "        bgr_crop = cv2.resize(bgr_crop, (w*scale, h*scale), interpolation=cv2.INTER_CUBIC)\n",
    "    img_t = val_transform(bgr_crop)  # PIL conversion inside transform\n",
    "    img_t = img_t.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_t)\n",
    "        probs = softmax(logits).cpu().numpy()[0]  # [prob_real, prob_spoof] if your training order is same\n",
    "    # NOTE: depending on your train label order, index 1 may correspond to 'spoof'\n",
    "    # We assume ImageFolder ordering: class_names = ['real','spoof'] so index 1 = spoof\n",
    "    spoof_prob = float(probs[1])\n",
    "    return spoof_prob\n",
    "\n",
    "def multi_scale_predict(frame, box, scales=[1.0, 1.5], fft_weight=0.35):\n",
    "    # For a detected face box, run multiple scale crops and average results\n",
    "    h_img, w_img = frame.shape[:2]\n",
    "    probs = []\n",
    "    for s in scales:\n",
    "        bx = expand_box(box, s, w_img, h_img)\n",
    "        crop = frame[bx[1]:bx[3], bx[0]:bx[2]]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "        p = predict_on_crop(crop)\n",
    "        probs.append(p)\n",
    "    if len(probs) == 0:\n",
    "        avg_p = 0.0\n",
    "    else:\n",
    "        avg_p = float(np.mean(probs))\n",
    "    # compute fft score on base box (scale=1.0) to provide spectral cue\n",
    "    bx0 = expand_box(box, 1.0, w_img, h_img)\n",
    "    crop0 = frame[bx0[1]:bx0[3], bx0[0]:bx0[2]]\n",
    "    if crop0.size == 0:\n",
    "        fft_score = 0.0\n",
    "    else:\n",
    "        fft_score = fft_spoof_score(crop0)\n",
    "    # combine: final_spoof_prob = (1 - alpha)*cnn + alpha*fft_score\n",
    "    alpha = fft_weight\n",
    "    final_spoof = alpha * fft_score + (1 - alpha) * avg_p\n",
    "    return final_spoof, avg_p, fft_score\n",
    "\n",
    "# -----------------------\n",
    "# Video capture and main loop\n",
    "# -----------------------\n",
    "cap = cv2.VideoCapture(0)  # change index if you have multiple cams\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera. Change camera index or check permissions.\")\n",
    "\n",
    "print(\"Starting webcam. Press 'q' to quit.\")\n",
    "fps_time = time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame\")\n",
    "        break\n",
    "    FRAME_COUNTER += 1\n",
    "    h_img, w_img = frame.shape[:2]\n",
    "\n",
    "    # ---------- 1) Detect faces ----------\n",
    "    boxes = []\n",
    "    if use_retina:\n",
    "        try:\n",
    "            # RetinaFace.detect_faces returns dict keyed by idx with 'facial_area'\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            if isinstance(faces, dict):\n",
    "                for k, v in faces.items():\n",
    "                    if 'facial_area' in v:\n",
    "                        x1,y1,x2,y2 = v['facial_area']\n",
    "                        # ensure ints\n",
    "                        boxes.append((int(x1), int(y1), int(x2), int(y2)))\n",
    "            elif faces is None:\n",
    "                boxes = []\n",
    "        except Exception as e:\n",
    "            # fallback to MTCNN\n",
    "            if detector is not None:\n",
    "                bbs = detector.detect(frame)\n",
    "                if bbs[0] is not None:\n",
    "                    for bb in bbs[0]:\n",
    "                        x1,y1,x2,y2 = bb\n",
    "                        boxes.append((int(x1), int(y1), int(x2), int(y2)))\n",
    "    else:\n",
    "        # MTCNN path\n",
    "        try:\n",
    "            bbs, _ = detector.detect(frame)\n",
    "            if bbs is not None:\n",
    "                for bb in bbs:\n",
    "                    x1,y1,x2,y2 = bb\n",
    "                    boxes.append((int(x1), int(y1), int(x2), int(y2)))\n",
    "        except Exception as e:\n",
    "            boxes = []\n",
    "\n",
    "    # ---------- 2) Track linking (simple IOU) ----------\n",
    "    # mark all existing tracks as not updated\n",
    "    for tr in tracks:\n",
    "        tr.last_seen += 1\n",
    "\n",
    "    assigned = []\n",
    "    new_tracks = []\n",
    "    for box in boxes:\n",
    "        # find best matching existing track by IOU\n",
    "        best_iou = 0.0\n",
    "        best_track = None\n",
    "        for tr in tracks:\n",
    "            i = iou(box, tr.box)\n",
    "            if i > best_iou:\n",
    "                best_iou = i\n",
    "                best_track = tr\n",
    "        if best_iou >= IOU_MATCH_THRESH and best_track is not None:\n",
    "            # update track\n",
    "            best_track.box = box\n",
    "            best_track.last_seen = 0\n",
    "            best_track.last_center = ((box[0]+box[2])/2, (box[1]+box[3])/2)\n",
    "            assigned.append(box)\n",
    "        else:\n",
    "            # create new track\n",
    "            global next_track_id\n",
    "            tr = Track(box, next_track_id)\n",
    "            next_track_id += 1\n",
    "            tracks.append(tr)\n",
    "            assigned.append(box)\n",
    "\n",
    "    # remove old tracks > 30 frames not seen\n",
    "    tracks = [tr for tr in tracks if tr.last_seen <= 30]\n",
    "\n",
    "    # ---------- 3) Per-face prediction and smoothing ----------\n",
    "    labels_for_draw = []\n",
    "    for tr in tracks:\n",
    "        # compute combined spoof probability via multi-scale cnn + fft\n",
    "        spoof_prob, cnn_p, fft_p = multi_scale_predict(frame, tr.box, scales=[1.0, 1.5], fft_weight=0.35)\n",
    "        # push into track queue and compute smoothed prob\n",
    "        tr.pred_queue.append(spoof_prob)\n",
    "        smoothed_spoof = float(np.mean(tr.pred_queue))\n",
    "        # also compute variance; if high variance, reduce confidence\n",
    "        var = float(np.var(tr.pred_queue)) if len(tr.pred_queue) > 0 else 0.0\n",
    "        # compute final confidence\n",
    "        # convert to label: threshold 0.5 -> spoof\n",
    "        label = \"SPOOF\" if smoothed_spoof >= 0.5 else \"REAL\"\n",
    "        conf = smoothed_spoof if label==\"SPOOF\" else (1.0 - smoothed_spoof)\n",
    "        # reduce confidence if track is short or high variance or small box\n",
    "        box_w = tr.box[2]-tr.box[0]; box_h = tr.box[3]-tr.box[1]\n",
    "        if len(tr.pred_queue) < 3:\n",
    "            conf *= 0.7\n",
    "        if var > 0.02:\n",
    "            conf *= 0.85\n",
    "        if max(box_w, box_h) < 80:\n",
    "            conf *= 0.8\n",
    "\n",
    "        labels_for_draw.append((tr.box, label, conf, smoothed_spoof, cnn_p, fft_p, tr.id))\n",
    "\n",
    "    # ---------- 4) Draw boxes and labels ----------\n",
    "    # draw in-frame\n",
    "    for box, label, conf, smoothed_spoof, cnn_p, fft_p, tid in labels_for_draw:\n",
    "        x1,y1,x2,y2 = box\n",
    "        color = (0,255,0) if label==\"REAL\" else (0,0,255)\n",
    "        thickness = 2\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), color, thickness)\n",
    "        text = f\"ID:{tid} {label} {conf*100:.0f}%\"\n",
    "        cv2.putText(frame, text, (x1, max(15, y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        # small debug overlay: cnn prob and fft\n",
    "        dbg = f\"CNN:{cnn_p:.2f} FFT:{fft_p:.2f}\"\n",
    "        cv2.putText(frame, dbg, (x1, y2+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "\n",
    "    # ---------- 5) Show frame and handle quit ----------\n",
    "    cv2.imshow(\"AntiSpoof Live\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
